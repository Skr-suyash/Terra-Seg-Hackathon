{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-08T13:49:44.249355Z",
     "iopub.status.busy": "2026-02-08T13:49:44.248617Z",
     "iopub.status.idle": "2026-02-08T16:50:24.260246Z",
     "shell.execute_reply": "2026-02-08T16:50:24.259339Z",
     "shell.execute_reply.started": "2026-02-08T13:49:44.249322Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Hardware: Tesla T4 x 2\n",
      "üë®‚Äçüè´ Loading Teacher (mit_b2) to generate Pseudo-Labels...\n",
      "üîÑ Generating labels for 1002 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd41219fe8a446ca958ad0fca5e35362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1.238] global loadsave.cpp:1063 imwrite_ Unsupported depth image for selected encoder is fallbacked to CV_8U.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generated 1002 pseudo-masks in 'pseudo_masks'\n",
      "\n",
      "üéì Training Student Model: mit_b3...\n",
      "üìö Dataset: 3174 Real + 1002 Pseudo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0910a88bc50b4cdfb1f304eef334e0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/135 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935c5d63ea6742b391a0d630f8f51f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/178M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/748777543.py:238: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 1/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/748777543.py:254: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/tmp/ipykernel_55/748777543.py:270: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(): preds = model(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Student Val IoU: 0.8680\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.8680\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 2/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Student Val IoU: 0.8681\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.8681\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 3/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Student Val IoU: 0.8857\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.8857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 4/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Student Val IoU: 0.8881\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.8881\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 5/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Student Val IoU: 0.8914\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.8914\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 6/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Student Val IoU: 0.8938\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.8938\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 7/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Student Val IoU: 0.8951\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.8951\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 8/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Student Val IoU: 0.8959\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.8959\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 9/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Student Val IoU: 0.8972\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.8972\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 10/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Student Val IoU: 0.8980\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.8980\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 11/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Student Val IoU: 0.8983\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.8983\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 12/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Student Val IoU: 0.8986\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.8986\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 13/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Student Val IoU: 0.8989\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.8989\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 14/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Student Val IoU: 0.9001\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.9001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 15/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Student Val IoU: 0.9008\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.9008\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 16/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Student Val IoU: 0.9002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 17/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Student Val IoU: 0.9009\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.9009\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 18/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Student Val IoU: 0.9017\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.9017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 19/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Student Val IoU: 0.9020\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.9020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 20/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Student Val IoU: 0.9026\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.9026\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 21/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Student Val IoU: 0.9019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 22/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Student Val IoU: 0.9023\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 23/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Student Val IoU: 0.9031\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.9031\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 24/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Student Val IoU: 0.9038\n",
      "üèÜ NEW STUDENT BEST! IoU: 0.9038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='weights/best_student_b3.pth' target='_blank'>weights/best_student_b3.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/weights/best_student_b3.pth"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 25/25:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Student Val IoU: 0.9031\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "# 1. INSTALL SMP\n",
    "try:\n",
    "    import segmentation_models_pytorch as smp\n",
    "except ImportError:\n",
    "    print(\"‚¨áÔ∏è Installing segmentation_models_pytorch...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"segmentation-models-pytorch\"])\n",
    "    import segmentation_models_pytorch as smp\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "CONFIG = {\n",
    "    \"ROOT_DIR\": \"/kaggle/input/terra-seg-rugged-terrain-segmentation/offroad-seg-kaggle/\",\n",
    "    \"TEACHER_WEIGHTS\": \"weights/best_model.pth\",  # Your current best B2 model\n",
    "    \"PSEUDO_DIR\": \"pseudo_masks\",                 # Where we save fake labels\n",
    "    \n",
    "    # STUDENT CONFIG (The Upgrade)\n",
    "    \"STUDENT_ARCH\": \"mit_b3\",        # UPGRADE: B2 -> B3 (Better Encoder)\n",
    "    \"INPUT_SIZE\": (512, 512),        # Keep 512 for B3 memory safety\n",
    "    \"BATCH_SIZE\": 8,                 # Lower batch size for B3 on T4\n",
    "    \"EPOCHS\": 25,\n",
    "    \"LR\": 2e-4,                      # Slightly lower LR for fine-tuning\n",
    "    \"CONFIDENCE_THR\": 0.95,          # Only trust high-confidence predictions\n",
    "    \"FOREGROUND_IDS\": [7100, 10000]\n",
    "}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üî• Hardware: {torch.cuda.get_device_name(0)} x {torch.cuda.device_count()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART 1: THE TEACHER (Generator)\n",
    "# =============================================================================\n",
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Must match your saved B2 model structure\n",
    "        self.model = smp.Unet(encoder_name=\"mit_b2\", classes=1, decoder_use_batchnorm=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def generate_pseudo_labels():\n",
    "    print(\"üë®‚Äçüè´ Loading Teacher (mit_b2) to generate Pseudo-Labels...\")\n",
    "    \n",
    "    if not os.path.exists(CONFIG[\"TEACHER_WEIGHTS\"]):\n",
    "        print(\"‚ùå Error: Teacher weights not found! Train the B2 model first.\")\n",
    "        return False\n",
    "\n",
    "    # Load Teacher\n",
    "    teacher = TeacherModel().to(device)\n",
    "    state_dict = torch.load(CONFIG[\"TEACHER_WEIGHTS\"], map_location=device)\n",
    "    # Fix module prefix\n",
    "    teacher.load_state_dict({k.replace(\"module.\", \"\"): v for k, v in state_dict.items()})\n",
    "    \n",
    "    if torch.cuda.device_count() > 1: teacher = nn.DataParallel(teacher)\n",
    "    teacher.eval()\n",
    "    \n",
    "    # Prepare Output Dir\n",
    "    os.makedirs(CONFIG[\"PSEUDO_DIR\"], exist_ok=True)\n",
    "    \n",
    "    # Get Test Images\n",
    "    test_dir = os.path.join(CONFIG[\"ROOT_DIR\"], \"test_images_padded\")\n",
    "    if not os.path.exists(test_dir): test_dir = os.path.join(CONFIG[\"ROOT_DIR\"], \"test_images\")\n",
    "    test_files = sorted(glob.glob(os.path.join(test_dir, \"*.*\")))\n",
    "    \n",
    "    print(f\"üîÑ Generating labels for {len(test_files)} images...\")\n",
    "    \n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for img_path in tqdm(test_files):\n",
    "            # Load & Preprocess\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            orig_w, orig_h = image.size\n",
    "            \n",
    "            # Resize to training size for prediction (faster)\n",
    "            input_tensor = T.functional.resize(image, CONFIG[\"INPUT_SIZE\"])\n",
    "            input_tensor = T.functional.to_tensor(input_tensor).unsqueeze(0).to(device)\n",
    "            input_tensor = T.functional.normalize(input_tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            \n",
    "            # Predict (Flip TTA)\n",
    "            pred = torch.sigmoid(teacher(input_tensor))\n",
    "            pred_flip = torch.sigmoid(teacher(torch.flip(input_tensor, dims=[3])))\n",
    "            pred_avg = (pred + torch.flip(pred_flip, dims=[3])) / 2.0\n",
    "            \n",
    "            # Filter by Confidence (Soft Labeling)\n",
    "            # We save the binary mask where confidence is high\n",
    "            mask = (pred_avg > 0.5).float().cpu().numpy()[0,0]\n",
    "            confidence = pred_avg.max().item()\n",
    "            \n",
    "            # Only save if model is somewhat sure (Optional: skip low conf images)\n",
    "            # Here we save all, but you can add: if confidence < 0.8: continue\n",
    "            \n",
    "            # Resize back to original size for saving\n",
    "            mask = cv2.resize(mask, (orig_w, orig_h), interpolation=cv2.INTER_NEAREST)\n",
    "            \n",
    "            # Save as PNG\n",
    "            save_name = os.path.basename(img_path).replace(\".jpg\", \".png\")\n",
    "            cv2.imwrite(os.path.join(CONFIG[\"PSEUDO_DIR\"], save_name), mask * 255)\n",
    "            count += 1\n",
    "            \n",
    "    print(f\"‚úÖ Generated {count} pseudo-masks in '{CONFIG['PSEUDO_DIR']}'\")\n",
    "    return True\n",
    "\n",
    "# =============================================================================\n",
    "# PART 2: THE STUDENT (Dataset & Model)\n",
    "# =============================================================================\n",
    "class PseudoDataset(Dataset):\n",
    "    def __init__(self, root_dir, pseudo_dir, split='train'):\n",
    "        self.split = split\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "        # 1. Real Data\n",
    "        self.real_img_dir = os.path.join(root_dir, 'train_images')\n",
    "        self.real_mask_dir = os.path.join(root_dir, 'train_masks')\n",
    "        self.real_images = sorted(glob.glob(os.path.join(self.real_img_dir, \"*.*\")))\n",
    "        \n",
    "        # 2. Pseudo Data (Only for training)\n",
    "        self.pseudo_images = []\n",
    "        if split == 'train' and os.path.exists(pseudo_dir):\n",
    "            # We look for test images that have a matching mask in pseudo_dir\n",
    "            test_img_dir = os.path.join(root_dir, 'test_images_padded')\n",
    "            if not os.path.exists(test_img_dir): test_img_dir = os.path.join(root_dir, 'test_images')\n",
    "            \n",
    "            candidates = sorted(glob.glob(os.path.join(test_img_dir, \"*.*\")))\n",
    "            for img_p in candidates:\n",
    "                mask_name = os.path.basename(img_p).replace(\".jpg\", \".png\")\n",
    "                if os.path.exists(os.path.join(pseudo_dir, mask_name)):\n",
    "                    self.pseudo_images.append((img_p, os.path.join(pseudo_dir, mask_name)))\n",
    "            \n",
    "            print(f\"üìö Dataset: {len(self.real_images)} Real + {len(self.pseudo_images)} Pseudo\")\n",
    "\n",
    "        self.color_jitter = T.ColorJitter(0.2, 0.2, 0.2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.real_images) + len(self.pseudo_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Determine if Real or Pseudo\n",
    "        if idx < len(self.real_images):\n",
    "            # REAL DATA\n",
    "            img_path = self.real_images[idx]\n",
    "            basename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            \n",
    "            # Try png/jpg mask\n",
    "            mask_path = os.path.join(self.real_mask_dir, basename + \".png\")\n",
    "            if not os.path.exists(mask_path): mask_path = os.path.join(self.real_mask_dir, basename + \".jpg\")\n",
    "            \n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            if os.path.exists(mask_path):\n",
    "                mask_src = np.array(Image.open(mask_path))\n",
    "                mask = np.zeros_like(mask_src, dtype=np.uint8)\n",
    "                for fg in CONFIG[\"FOREGROUND_IDS\"]: mask[mask_src == fg] = 1\n",
    "                mask = Image.fromarray(mask * 255)\n",
    "            else:\n",
    "                mask = Image.fromarray(np.zeros((image.size[1], image.size[0]), dtype=np.uint8))\n",
    "        else:\n",
    "            # PSEUDO DATA\n",
    "            p_idx = idx - len(self.real_images)\n",
    "            img_path, mask_path = self.pseudo_images[p_idx]\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            mask = Image.open(mask_path).convert(\"L\") # Already binary 0-255\n",
    "\n",
    "        # Resize & Augment\n",
    "        if self.split == 'train':\n",
    "            # Resize if too small\n",
    "            if image.size[0] < CONFIG[\"INPUT_SIZE\"][0]:\n",
    "                image = T.functional.resize(image, CONFIG[\"INPUT_SIZE\"])\n",
    "                mask = T.functional.resize(mask, CONFIG[\"INPUT_SIZE\"], interpolation=T.InterpolationMode.NEAREST)\n",
    "            \n",
    "            # Random Crop\n",
    "            i, j, h, w = T.RandomCrop.get_params(image, output_size=CONFIG[\"INPUT_SIZE\"])\n",
    "            image = T.functional.crop(image, i, j, h, w)\n",
    "            mask = T.functional.crop(mask, i, j, h, w)\n",
    "            \n",
    "            # Augment\n",
    "            if random.random() < 0.5:\n",
    "                image = T.functional.hflip(image)\n",
    "                mask = T.functional.hflip(mask)\n",
    "            if random.random() < 0.3:\n",
    "                 image = self.color_jitter(image)\n",
    "        else:\n",
    "            image = T.functional.resize(image, CONFIG[\"INPUT_SIZE\"])\n",
    "            mask = T.functional.resize(mask, CONFIG[\"INPUT_SIZE\"], interpolation=T.InterpolationMode.NEAREST)\n",
    "\n",
    "        # To Tensor\n",
    "        image = T.functional.to_tensor(image)\n",
    "        image = T.functional.normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        mask = T.functional.to_tensor(mask)\n",
    "        mask = (mask > 0.5).float()\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "# =============================================================================\n",
    "# PART 3: TRAINING LOOP (The Student)\n",
    "# =============================================================================\n",
    "def train_student():\n",
    "    print(f\"\\nüéì Training Student Model: {CONFIG['STUDENT_ARCH']}...\")\n",
    "    \n",
    "    # 1. Dataset\n",
    "    full_ds = PseudoDataset(CONFIG[\"ROOT_DIR\"], CONFIG[\"PSEUDO_DIR\"], split='train')\n",
    "    \n",
    "    # Validation only on REAL data (don't validate on pseudo labels!)\n",
    "    train_size = int(0.9 * len(full_ds)) # Use more data for training\n",
    "    val_size = len(full_ds) - train_size\n",
    "    train_ds, val_ds = torch.utils.data.random_split(full_ds, [train_size, val_size])\n",
    "    val_ds.dataset.split = 'val'\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=CONFIG[\"BATCH_SIZE\"], shuffle=True, num_workers=4, drop_last=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=CONFIG[\"BATCH_SIZE\"], shuffle=False, num_workers=4)\n",
    "    \n",
    "    # 2. Student Model (MIT_B3 - The Upgrade)\n",
    "    model = smp.Unet(\n",
    "        encoder_name=CONFIG[\"STUDENT_ARCH\"], \n",
    "        encoder_weights=\"imagenet\", \n",
    "        in_channels=3, classes=1, decoder_use_batchnorm=True\n",
    "    ).to(device)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1: model = nn.DataParallel(model)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG[\"LR\"], weight_decay=1e-2)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Loss: Weighted heavily towards Dice for fine-tuning\n",
    "    loss_fn = smp.losses.DiceLoss(mode='binary', from_logits=True)\n",
    "    bce_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    best_score = 0.0\n",
    "    \n",
    "    for epoch in range(CONFIG[\"EPOCHS\"]):\n",
    "        model.train()\n",
    "        loop = tqdm(train_loader, desc=f\"Ep {epoch+1}/{CONFIG['EPOCHS']}\", leave=False)\n",
    "        \n",
    "        for imgs, masks in loop:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                preds = model(imgs)\n",
    "                # 70% Dice (Shape), 30% BCE (Pixel accuracy)\n",
    "                loss = 0.7 * loss_fn(preds, masks) + 0.3 * bce_fn(preds, masks)\n",
    "                \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "            \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_iou = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in val_loader:\n",
    "                imgs, masks = imgs.to(device), masks.to(device)\n",
    "                with autocast(): preds = model(imgs)\n",
    "                \n",
    "                pred_mask = (torch.sigmoid(preds) > 0.5).float()\n",
    "                inter = (pred_mask * masks).sum()\n",
    "                union = pred_mask.sum() + masks.sum() - inter\n",
    "                val_iou += (inter + 1e-6) / (union + 1e-6)\n",
    "                \n",
    "        avg_iou = val_iou / len(val_loader)\n",
    "        print(f\"Epoch {epoch+1} | Student Val IoU: {avg_iou:.4f}\")\n",
    "        \n",
    "        if avg_iou > best_score:\n",
    "            best_score = avg_iou\n",
    "            # Save as 'best_student.pth' to differentiate\n",
    "            torch.save(model.state_dict(), \"weights/best_student_b3.pth\")\n",
    "            print(f\"üèÜ NEW STUDENT BEST! IoU: {best_score:.4f}\")\n",
    "            display(FileLink(\"weights/best_student_b3.pth\"))\n",
    "\n",
    "# =============================================================================\n",
    "# EXECUTION\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Generate Labels\n",
    "    success = generate_pseudo_labels()\n",
    "    \n",
    "    # Step 2: Train Student if labels exist\n",
    "    if success:\n",
    "        train_student()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the paths section - \n",
    "\n",
    "DATA_ROOT - Your root directory path\n",
    "\n",
    "WEIGHTS_PATH - Insert your model path here\n",
    "\n",
    "TEST_DIR - Insert your test image path here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T16:55:35.436600Z",
     "iopub.status.busy": "2026-02-08T16:55:35.436285Z",
     "iopub.status.idle": "2026-02-08T17:04:47.588187Z",
     "shell.execute_reply": "2026-02-08T17:04:47.587416Z",
     "shell.execute_reply.started": "2026-02-08T16:55:35.436574Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Hardware Detected: Tesla T4 x 2\n",
      "‚öôÔ∏è Loading Student Model (mit_b3)...\n",
      "üìñ Reading weights from weights/best_student_b3.pth...\n",
      "‚úÖ Student Weights Loaded Successfully.\n",
      "üöÄ Processing 1002 images using Multi-Scale TTA [0.75, 1.0, 1.25]...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841762039db64655b97767c22597ede6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/2353206082.py:86: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ INFERENCE COMPLETE!\n",
      "üìä Processed 1002 images.\n",
      "‚¨áÔ∏è CLICK BELOW TO DOWNLOAD YOUR SUBMISSION:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='submission.csv' target='_blank'>submission.csv</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/submission.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import torchvision.transforms as T\n",
    "from IPython.display import FileLink, display\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & CONFIGURATION\n",
    "# ==========================================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üî• Hardware Detected: {torch.cuda.get_device_name(0)} x {torch.cuda.device_count()}\")\n",
    "\n",
    "# Paths\n",
    "DATA_ROOT = \"/kaggle/input/terra-seg-rugged-terrain-segmentation/offroad-seg-kaggle/\"\n",
    "\n",
    "WEIGHTS_PATH = \"weights/best_student_b3.pth\"  \n",
    "\n",
    "TEST_DIR = os.path.join(DATA_ROOT, \"test_images_padded\")\n",
    "\n",
    "# Fallback to standard folder if padded doesn't exist\n",
    "if not os.path.exists(TEST_DIR):\n",
    "    print(f\"‚ö†Ô∏è Padded folder not found. Falling back to standard test_images...\")\n",
    "    TEST_DIR = os.path.join(DATA_ROOT, \"test_images\")\n",
    "\n",
    "# TTA Configuration\n",
    "TTA_SCALES = [0.75, 1.0, 1.25]  # The \"Holy Grail\" scales\n",
    "\n",
    "# ==========================================\n",
    "# 2. MODEL ARCHITECTURE (Student mit_b3)\n",
    "# ==========================================\n",
    "def get_student_model():\n",
    "    \"\"\"\n",
    "    Returns the exact model structure used in Student Training.\n",
    "    Crucial: Must match 'mit_b3' if you trained the student with b3.\n",
    "    \"\"\"\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"mit_b3\",       # <--- The Student Encoder\n",
    "        encoder_weights=None,        # Weights are loaded later\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "        decoder_use_batchnorm=True,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ==========================================\n",
    "# 3. HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "def rle_encode(mask):\n",
    "    \"\"\"Encodes a binary mask to RLE format for Kaggle.\"\"\"\n",
    "    pixels = mask.flatten(order=\"F\")\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def predict_multiscale_tta(model, image_tensor, scales=TTA_SCALES):\n",
    "    \"\"\"\n",
    "    Runs inference at multiple scales with horizontal flip TTA.\n",
    "    Returns the average probability map.\n",
    "    \"\"\"\n",
    "    b, c, h, w = image_tensor.shape\n",
    "    final_output = torch.zeros((b, 1, h, w), device=device)\n",
    "    \n",
    "    # Loop through scales\n",
    "    for scale in scales:\n",
    "        # 1. Resize Input (if needed)\n",
    "        if scale != 1.0:\n",
    "            new_h, new_w = int(h * scale), int(w * scale)\n",
    "            # Ensure divisible by 32 (SegFormer requirement)\n",
    "            new_h = int(np.ceil(new_h / 32) * 32)\n",
    "            new_w = int(np.ceil(new_w / 32) * 32)\n",
    "            \n",
    "            input_scaled = F.interpolate(\n",
    "                image_tensor, size=(new_h, new_w), mode='bilinear', align_corners=False\n",
    "            )\n",
    "        else:\n",
    "            input_scaled = image_tensor\n",
    "\n",
    "        # 2. Predict (Original + Flip)\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                # Forward Pass\n",
    "                pred = torch.sigmoid(model(input_scaled))\n",
    "                \n",
    "                # Flip Pass (Horizontal)\n",
    "                pred_flip = torch.sigmoid(model(torch.flip(input_scaled, dims=[3])))\n",
    "                pred_flip = torch.flip(pred_flip, dims=[3])\n",
    "        \n",
    "        # 3. Average Flip & Original\n",
    "        pred_avg = (pred + pred_flip) / 2.0\n",
    "        \n",
    "        # 4. Resize back to original target size (1.0x)\n",
    "        if scale != 1.0:\n",
    "            pred_avg = F.interpolate(\n",
    "                pred_avg, size=(h, w), mode='bilinear', align_corners=False\n",
    "            )\n",
    "            \n",
    "        final_output += pred_avg\n",
    "\n",
    "    # Average over all scales\n",
    "    final_output /= len(scales)\n",
    "    return final_output\n",
    "\n",
    "# ==========================================\n",
    "# 4. MAIN INFERENCE ENGINE\n",
    "# ==========================================\n",
    "def run_inference():\n",
    "    if not os.path.exists(WEIGHTS_PATH):\n",
    "        print(f\"‚ùå Critical Error: '{WEIGHTS_PATH}' not found!\")\n",
    "        print(\"   Did you run the Student Training cell successfully?\")\n",
    "        return\n",
    "\n",
    "    # 1. Load Model\n",
    "    print(\"‚öôÔ∏è Loading Student Model (mit_b3)...\")\n",
    "    model = get_student_model()\n",
    "    \n",
    "    # 2. Load Weights (Robust Fix for 'module.' prefix)\n",
    "    print(f\"üìñ Reading weights from {WEIGHTS_PATH}...\")\n",
    "    state_dict = torch.load(WEIGHTS_PATH, map_location=device)\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        # Strip 'module.' if it exists (from DataParallel training)\n",
    "        k = k.replace(\"module.\", \"\") \n",
    "        new_state_dict[k] = v\n",
    "        \n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(\"‚úÖ Student Weights Loaded Successfully.\")\n",
    "\n",
    "    # 3. Process Images\n",
    "    test_files = sorted(glob.glob(os.path.join(TEST_DIR, \"*.*\")))\n",
    "    print(f\"üöÄ Processing {len(test_files)} images using Multi-Scale TTA {TTA_SCALES}...\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Batch processing loop\n",
    "    for img_path in tqdm(test_files):\n",
    "        try:\n",
    "            img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            \n",
    "            # Load\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            \n",
    "            # Preprocess (Standard ImageNet Normalization)\n",
    "            input_tensor = T.functional.to_tensor(image).unsqueeze(0).to(device)\n",
    "            input_tensor = T.functional.normalize(input_tensor, \n",
    "                                                  mean=[0.485, 0.456, 0.406], \n",
    "                                                  std=[0.229, 0.224, 0.225])\n",
    "            \n",
    "            # INFERENCE: Multi-Scale TTA\n",
    "            pred_mask = predict_multiscale_tta(model, input_tensor, scales=TTA_SCALES)\n",
    "            \n",
    "            # Binarize (Threshold 0.5)\n",
    "            pred_mask_np = (pred_mask > 0.5).float().cpu().numpy().astype(np.uint8)[0, 0]\n",
    "            \n",
    "            # RLE Encode\n",
    "            rle = rle_encode(pred_mask_np)\n",
    "            results.append({'image_id': img_name, 'encoded_pixels': rle})\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error on {img_name}: {e}\")\n",
    "            \n",
    "    # 4. Save Submission\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(\"submission.csv\", index=False)\n",
    "    \n",
    "    print(\"\\n‚úÖ INFERENCE COMPLETE!\")\n",
    "    print(f\"üìä Processed {len(results)} images.\")\n",
    "    print(\"‚¨áÔ∏è CLICK BELOW TO DOWNLOAD YOUR SUBMISSION:\")\n",
    "    display(FileLink(\"submission.csv\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_inference()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 15603876,
     "sourceId": 127593,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
